# -*- coding: utf-8 -*-
"""Inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ahYgrT2KdQ_hIXfa3ap1C9yMvbi5Z8FI
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pymupdf

pip install 'git+https://github.com/facebookresearch/detectron2.git'

!pip install transformers

!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

!pip install opencv-python pillow numpy pymupdf pandas tqdm

import zipfile

zip_path = "/content/drive/MyDrive/DataMorphAI/Trained models/final_model_trOCR.zip"
extract_to = "/content/drive/MyDrive/DataMorphAI/Trained models/final_model_trOCR"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("TrOCR model extracted to:", extract_to)

import os
import fitz  # PyMuPDF
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import detectron2
from detectron2.utils.logger import setup_logger
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
import json
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from pathlib import Path
print("All imports loaded successfully!")
print(f"PyTorch version: {torch.__version__}")
print(f"Detectron2 version: {detectron2.__version__}")

def setup_detectron2_model(weights_path, score_threshold=0.2):
    cfg = get_cfg()

    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
    cfg.MODEL.WEIGHTS = weights_path
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_threshold
    cfg.MODEL.DEVICE = "cuda"
    predictor = DefaultPredictor(cfg)
    return predictor

detectron2_weights = "/content/drive/MyDrive/DataMorphAI/Trained models/line_detector_model30v2.pth"

det_predictor = setup_detectron2_model(detectron2_weights)

print("Detectron2 line detector loaded perfectly!")
print(f"Model path: {detectron2_weights}")

trocr_base_path = "/content/drive/MyDrive/DataMorphAI/Trained models/final_model_trOCR/final_model/"

print("Checking nested TrOCR model files:")
for file in os.listdir(trocr_base_path):
    print(f"  - {file}")

from transformers import TrOCRProcessor, VisionEncoderDecoderModel

trocr_processor = TrOCRProcessor.from_pretrained(trocr_base_path)
trocr_model = VisionEncoderDecoderModel.from_pretrained(trocr_base_path)

trocr_model.to("cuda")
trocr_model.eval()

print("TrOCR model loaded successfully")

import fitz
import os
import cv2
import numpy as np
from google.colab import files
from tqdm import tqdm
from google.colab.patches import cv2_imshow

def pdf_to_images(pdf_path, zoom_x=2.0, zoom_y=2.0):
    doc = fitz.open(pdf_path)
    images = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(zoom_x, zoom_y)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
        if pix.n == 4:
            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
        images.append(img)
    doc.close()
    return images

uploaded_files = files.upload()
pdf_path = list(uploaded_files.keys())[0]
print(f"Uploaded PDF: {pdf_path}")

page_images = pdf_to_images(pdf_path)
print(f"Converted {len(page_images)} pages to images!")

all_page_boxes = []
for page_num, page_img in enumerate(tqdm(page_images, desc="Detecting lines")):
    outputs = det_predictor(page_img)
    instances = outputs["instances"].to("cpu")
    boxes = instances.pred_boxes.tensor.numpy()
    all_page_boxes.append(boxes)

print(f"Detection complete for {len(all_page_boxes)} pages!")

print("Showing bounding boxes for first 2 pages:")
for page_num in range(min(2, len(page_images))):
    img_viz = page_images[page_num].copy()
    boxes = all_page_boxes[page_num]
    for box in boxes:
        x1, y1, x2, y2 = box.astype(int)
        cv2.rectangle(img_viz, (x1, y1), (x2, y2), (0,255,0), 2)
    print(f"Page {page_num+1}: {len(boxes)} lines detected")
    cv2_imshow(img_viz)

def extract_text_from_lines(image, boxes, processor, model):
    texts = []
    for i, box in enumerate(tqdm(boxes, desc="Extracting text")):
        x1, y1, x2, y2 = box.astype(int)
        h, w = image.shape[:2]
        pad = 10
        x1 = max(0, x1 - pad)
        y1 = max(0, y1 - pad)
        x2 = min(w, x2 + pad)
        y2 = min(h, y2 + pad)

        line_crop = image[y1:y2, x1:x2]
        pil_image = Image.fromarray(cv2.cvtColor(line_crop, cv2.COLOR_BGR2RGB))

        inputs = processor(images=pil_image, return_tensors="pt").to("cuda")
        with torch.no_grad():
            generated_ids = model.generate(**inputs, max_length=64)
            text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

        texts.append(text.strip())
    return texts

all_page_texts = []
for page_num, (page_img, boxes) in enumerate(tqdm(zip(page_images, all_page_boxes), desc="Processing pages")):
    page_texts = extract_text_from_lines(page_img, boxes, trocr_processor, trocr_model)
    all_page_texts.append(page_texts)
    print(f"Page {page_num+1}: {len(page_texts)} lines extracted")

print(f"Text extraction complete for {len(all_page_texts)} pages!")

def sort_lines_by_position(boxes, texts):
    line_data = []
    for box, text in zip(boxes, texts):
        y_center = (box[1] + box[3]) / 2
        line_data.append((y_center, text, box))
    line_data.sort(key=lambda x: x[0])
    sorted_texts = [item[1] for item in line_data]
    return sorted_texts

all_sorted_texts = []
for page_num, (boxes, texts) in enumerate(zip(all_page_boxes, all_page_texts)):
    sorted_texts = sort_lines_by_position(boxes, texts)
    all_sorted_texts.append(sorted_texts)
    print(f"Page {page_num+1}: {len(sorted_texts)} sorted lines")

def create_beautiful_pdf(all_texts, output_path, page_width=595, margin=50, font_size=14):
    doc = fitz.open()
    for page_num, texts in enumerate(all_texts):
        page = doc.new_page(width=page_width, height=842)
        y_pos = margin
        for text in texts:
            text_rect = fitz.Rect(margin, y_pos, margin + page_width - 2*margin, y_pos + 60)
            page.insert_textbox(text_rect, text.strip(),
                              fontsize=font_size, fontname="helv",
                              align=3,
                              color=(0,0,0))
            y_pos += font_size * 1.6
    doc.save(output_path)
    doc.close()
    return output_path

beautiful_pdf_path = "/content/multi_page_output.pdf"
create_beautiful_pdf(all_sorted_texts, beautiful_pdf_path)

print(f"Multi-page PDF generated: {beautiful_pdf_path}")
print(f"Total pages processed: {len(all_sorted_texts)}")
from google.colab import files
files.download(beautiful_pdf_path)

import pickle

with open("/content/detectron2_predictor.pkl", "wb") as f:
    pickle.dump(det_predictor, f)

print("Detectron2 predictor saved as detectron2_predictor.pkl")
from google.colab import files
files.download("/content/detectron2_predictor.pkl")

import pickle

trocr_bundle = {
    "processor": trocr_processor,
    "model": trocr_model
}

with open("/content/trocr_bundle.pkl", "wb") as f:
    pickle.dump(trocr_bundle, f)

print("TrOCR bundle saved as trocr_bundle.pkl")
files.download("/content/trocr_bundle.pkl")
import pickle

pipeline_functions = {
    "pdf_to_images": pdf_to_images,
    "extract_text_from_lines": extract_text_from_lines,
    "sort_lines_by_position": sort_lines_by_position,
    "create_beautiful_pdf": create_beautiful_pdf
}

with open("/content/pipeline_functions.pkl", "wb") as f:
    pickle.dump(pipeline_functions, f)

print("Pipeline functions saved as pipeline_functions.pkl")
files.download("/content/pipeline_functions.pkl")

